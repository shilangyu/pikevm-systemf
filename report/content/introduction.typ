#import "/prelude.typ": *

= Introduction <sec:intro>

Classical @regex:intro:plural have been studied for decades and are sometimes believed to be well understood. However, modern regular expressions used in programming languages have long strayed away from just describing regular languages. This is due to the addition of many modern regex features such as _backreferences_, _capture groups_, or _lookarounds_. While classically we were interested in the question of whether a regex accepts or rejects a word, modern regexes concern themselves with whether they matched a word, where they matched it, and how they matched it. Layering these new questions on top of the various modern regex features turn the matching problem into a much more difficult one. Combined with the need for regex matching to be fast in practice, real-world implementations are often buggy @bug-rust @bug-v8 and vulnerable to attacks @cloudflare-vuln @redos-study.

Real-world regex matching implementations are fast thanks to the large variety of optimizations and heuristics they employ. They skip parts of the @haystack:intro, they rewrite the regex into an equivalent one that is more efficiently matched, they combine multiple string search algorithms, they specialize commonly used patterns, they change strategies depending on memory usage, and much more. Unfortunately, this growing complexity and the resulting subtle interactions between those optimizations lead to implementations that are difficult to reason about. Formal verification gives us tools to address these issues by having a structured approach to reasoning. We can produce implementations that are provably correct (absence of bugs) and provably efficient (absence of performance vulnerabilities). Unfortunately, the real-world optimized algorithms full of heuristics go beyond what has been done in the state-of-the-art verified regex matching.

The goal of this work is to formally verify *real-world regex optimizations*. Since we do not wish to verify a toy regex matching algorithm, we will use the _Linden_ @linden project. _Linden_ provides a *complete* and *practical* mechanization of the #TODO[ECMAScript 2023 regexes][cite the spec] in the Rocq prover. It formalizes both the semantics of matching in addition to a verified matching algorithm following these semantics. Using Linden as the base gives us confidence that we are working with real-world regexes which include all of the ugly and cumbersome aspects. Building on this project we proved on the verified matching algorithm the correctness of the *prefix acceleration* optimization which can potentially skip very large portions of the haystack, *anchored searches* optimization which detects that a match can only appear at the start of the haystack, and *impossible matches* optimization which detects that a regex can never match any haystack.

In practice real-world implementations utilize multiple @engine:intro:plural to specialize searches for given regexes and haystacks. The choice of an engine is guided by heuristics. These heuristics use information such as which regex features were used and the length of the haystack. To protect ourselves from @redos:intro:cap attacks, we focus on engines that have worst-case linear execution with respect to the regex and haystack size. _Linden_ formalizes two such engines, the PikeVM @linden and the memoized backtracker. In this work we define and prove correctness of a *Meta engine* which deploys heuristics and optimizations using those base linear engines to considerably speed up matching.

#TODO[Add paragraph which outlines the sections and their achievements]
#TODO[Add paragraph which outlines the appendices]
#TODO[Mention that these are the first formal proofs of these things]
